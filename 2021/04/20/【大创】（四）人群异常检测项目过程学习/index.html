<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />



  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico?v=5.1.4">






  <meta name="keywords" content="python," />










<meta name="description" content="人群中的异常行为是一大潜在威胁,自动检测监控中的异常行为成为近年的研究热点之一。">
<meta property="og:type" content="article">
<meta property="og:title" content="【大创】（四）人群异常检测项目过程学习">
<meta property="og:url" content="https://chocofairy.github.io/2021/04/20/%E3%80%90%E5%A4%A7%E5%88%9B%E3%80%91%EF%BC%88%E5%9B%9B%EF%BC%89%E4%BA%BA%E7%BE%A4%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E9%A1%B9%E7%9B%AE%E8%BF%87%E7%A8%8B%E5%AD%A6%E4%B9%A0/index.html">
<meta property="og:site_name" content="巧克力梦工厂">
<meta property="og:description" content="人群中的异常行为是一大潜在威胁,自动检测监控中的异常行为成为近年的研究热点之一。">
<meta property="og:locale">
<meta property="article:published_time" content="2021-04-20T11:08:34.000Z">
<meta property="article:modified_time" content="2021-04-20T11:16:27.545Z">
<meta property="article:author" content="wlz">
<meta property="article:tag" content="python">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"hide","offset":20,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://ChocoFairy.github.io/2021/04/20/【大创】（四）人群异常检测项目过程学习/"/>





  <title>【大创】（四）人群异常检测项目过程学习 | 巧克力梦工厂</title>
  








<meta name="generator" content="Hexo 5.4.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">巧克力梦工厂</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">小仙女的个人博客</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ChocoFairy.github.io/2021/04/20/%E3%80%90%E5%A4%A7%E5%88%9B%E3%80%91%EF%BC%88%E5%9B%9B%EF%BC%89%E4%BA%BA%E7%BE%A4%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E9%A1%B9%E7%9B%AE%E8%BF%87%E7%A8%8B%E5%AD%A6%E4%B9%A0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/person.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="巧克力梦工厂">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">【大创】（四）人群异常检测项目过程学习</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-04-20T19:08:34+08:00">
                2021-04-20
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%A4%A7%E5%88%9B/" itemprop="url" rel="index">
                    <span itemprop="name">大创</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  11.9k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  61 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>人群中的异常行为是一大潜在威胁,自动检测监控中的异常行为成为近年的研究热点之一。</p>
<span id="more"></span>
<h2 id="一工具">一、工具</h2>
<p>今天在看github上各位大佬写的关于人群异常检测的代码的时候，发现了一个无敌好用的神器：<a target="_blank" rel="noopener" href="https://colab.research.google.com/notebooks/intro.ipynb">Google Colab</a>。</p>
<p>Colaboratory 简称“Colab”，是Google Research 团队开发的一款产品。 在Colab 中，任何人都可以通过浏览器编写和执行任意Python 代码。 它尤其适合机器学习、数据分析和教育目的。 从技术上说，Colab 是一种托管式Jupyter 笔记本服务。</p>
<p>简单地说，就是一款不需要安装各种机器学习环境的云端Jupyter Notebook！</p>
<p>下面的代码可以轻而易举的在Google Colab上跑通。</p>
<h2 id="二代码">二、代码</h2>
<h3 id="数据准备生成trainer.npy文件">1.数据准备（生成trainer.npy文件）</h3>
<p>我用的数据集来自于<a target="_blank" rel="noopener" href="http://www.cse.cuhk.edu.hk/leojia/projects/detectabnormal/dataset.html">Avenue training dataset</a>。下载完成之后，在根目录中的content目录下建立training_videos目录，并把下载好的数据集中的training_videos上传上去。（这里也可以根据自己代码编写的目录上传到不同的目录下）</p>
<p>新建ipynb文件开始编写代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">请确保您检查变量video_source_path指向包含训练数据集的文件夹</span></span><br><span class="line"><span class="string">并确保您上传了正确的培训视频而不是测试视频</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> img_to_array,load_img</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> os </span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data, color</span><br><span class="line"><span class="keyword">from</span> skimage.transform <span class="keyword">import</span> rescale, resize, downscale_local_mean</span><br><span class="line"><span class="comment">#rescale 按一定的因子缩放图像</span></span><br><span class="line"><span class="comment">#resize 调整图像的大小以匹配一定的大小</span></span><br><span class="line"><span class="comment">#downscale_local_mean 通过局部平均下采样N维图像。</span></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line">imagestore=[]</span><br><span class="line"></span><br><span class="line">video_source_path=<span class="string">&#x27;/content/training_videos&#x27;</span></span><br><span class="line"><span class="comment">#视频的路径</span></span><br><span class="line">fps=<span class="number">5</span></span><br><span class="line"><span class="comment">#fps是指拍摄一帧的秒数。fps = 5表示每5秒1帧。更像是帧/秒</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_dir</span>(<span class="params">path</span>):</span><span class="comment">#创建目录</span></span><br><span class="line">	<span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path):<span class="comment">#返回布尔值，如果路径存在，返回true，如果不存在，返回false</span></span><br><span class="line">		os.makedirs(path)<span class="comment">#如果路径不存在，利用makedirs方法创建目录</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">remove_old_images</span>(<span class="params">path</span>):</span><span class="comment">#删除旧的路径下的图片</span></span><br><span class="line">	filelist = glob.glob(os.path.join(path, <span class="string">&quot;*.png&quot;</span>))<span class="comment">#filelist用于存储传入路径中的所有图片</span></span><br><span class="line">  <span class="comment">#os.path.join()函数用于拼接文件的路径</span></span><br><span class="line">  <span class="comment">#glob()函数可以用来查找符合自己目的的文件，返回的文件名只包括当前目录里的文件名，不包括子文件夹里的文件。</span></span><br><span class="line">	<span class="keyword">for</span> f <span class="keyword">in</span> filelist:<span class="comment">#遍历filelist并删除文件里面的图片</span></span><br><span class="line">		os.remove(f)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">store</span>(<span class="params">image_path</span>):</span><span class="comment">#存储图片</span></span><br><span class="line">	img=load_img(image_path)<span class="comment">#对指定image_path的图片进行提取</span></span><br><span class="line">	img=img_to_array(img)<span class="comment">#把图片转换为numpy数组</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">#把图片调整为(227,227,3),以便于网络能够处理它</span></span><br><span class="line">	img=resize(img,(<span class="number">227</span>,<span class="number">227</span>,<span class="number">3</span>))</span><br><span class="line">  <span class="comment">#将图像转换为灰度图</span></span><br><span class="line">	gray=<span class="number">0.2989</span>*img[:,:,<span class="number">0</span>]+<span class="number">0.5870</span>*img[:,:,<span class="number">1</span>]+<span class="number">0.1140</span>*img[:,:,<span class="number">2</span>]</span><br><span class="line">  <span class="comment">#存储到ImageStore中</span></span><br><span class="line">	imagestore.append(gray)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#来源于video_source_path中的所有的视频列表</span></span><br><span class="line">videos=os.listdir(video_source_path)</span><br><span class="line">print(<span class="string">&quot;Found &quot;</span>,<span class="built_in">len</span>(videos),<span class="string">&quot; training videos&quot;</span>)<span class="comment">#打印结果是找到的视频数量</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#创建临时目录存储所有的帧</span></span><br><span class="line">create_dir(video_source_path+<span class="string">&#x27;/frames&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#去除之前的无用图片</span></span><br><span class="line">remove_old_images(video_source_path+<span class="string">&#x27;/frames&#x27;</span>)</span><br><span class="line"></span><br><span class="line">framepath=video_source_path+<span class="string">&#x27;/frames&#x27;</span><span class="comment">#创建framepath用来存储帧所在的路径</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> video <span class="keyword">in</span> videos:<span class="comment">#遍历videos视频列表</span></span><br><span class="line">		os.system( <span class="string">&#x27;ffmpeg -i &#123;&#125;/&#123;&#125; -r 1/&#123;&#125;  &#123;&#125;/frames/%03d.jpg&#x27;</span>.<span class="built_in">format</span>(video_source_path,video,fps,video_source_path))</span><br><span class="line">    <span class="comment">#format用于格式化字符串,这里是把os命令中加入视频路径等信息，format方法中每一个参数对应前面字符串中的一个&#123;&#125;</span></span><br><span class="line">    <span class="comment">#os.system用于执行系统命令，这里执行的是ffmpeg </span></span><br><span class="line">    <span class="comment">#-i是获取视频文件信息，对应的参数是video_source_path/video（路径）</span></span><br><span class="line">    <span class="comment">#-r是设置帧速度。即，每秒提取帧到图像的数字。默认值是25。这里对应的是参数fps</span></span><br><span class="line">    <span class="comment">#&#123;&#125;/frames/%03d.jpg 表示如何命名我们提取的图像，对应的参数是video_source_path</span></span><br><span class="line"></span><br><span class="line">		images=os.listdir(framepath)<span class="comment">#返回framepath指定的文件夹包含的文件或文件夹的名字的列表，存入images中</span></span><br><span class="line">		<span class="keyword">for</span> image <span class="keyword">in</span> images:</span><br><span class="line">      <span class="comment">#遍历images列表，将每张提取出来的帧转换(227,227,3)后转换为灰度图存到ImageStore数组中</span></span><br><span class="line">			image_path=framepath+ <span class="string">&#x27;/&#x27;</span>+ image</span><br><span class="line">			store(image_path)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">imagestore=np.array(imagestore)<span class="comment">#将imagestore转换为Numpy数组</span></span><br><span class="line">a,b,c=imagestore.shape<span class="comment">#用a,b,c存储数组的维度</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#重塑为（227,227，batch_size）</span></span><br><span class="line">imagestore.resize(b,c,a)</span><br><span class="line"><span class="comment">#归一化</span></span><br><span class="line">imagestore=(imagestore-imagestore.mean())/(imagestore.std())</span><br><span class="line"><span class="comment">#处理数组中的负值，0和1是限定的最小值和最大值</span></span><br><span class="line">imagestore=np.clip(imagestore,<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">np.save(<span class="string">&#x27;trainer.npy&#x27;</span>,imagestore)<span class="comment">#生成训练数据文件</span></span><br><span class="line"><span class="comment">#删除缓冲区目录</span></span><br><span class="line">os.system(<span class="string">&#x27;rm -r &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(framepath))<span class="comment">#rm -r是指递归删除目录，会事先删除目录中的内容后再删除目录</span></span><br><span class="line">print(<span class="string">&quot;Program ended. Please wait while trainer.npy is created. \nRefresh when needed&quot;</span>)</span><br><span class="line">print(<span class="string">&#x27;Number of frames created :&#x27;</span>, <span class="built_in">int</span>(<span class="built_in">len</span>(imagestore)))<span class="comment">#输出处理好的图像数组元素个数</span></span><br></pre></td></tr></table></figure>
<p>运行结果：</p>
<blockquote>
<p>Found 16 training videos</p>
<p>Program ended. Please wait while trainer.npy is created.</p>
<p>Refresh when needed</p>
<p>Number of frames created : 227</p>
</blockquote>
<p>因此，现在content目录下已经创建了一个名为trainer.npy的训练数据文件 在进入下一部分之前，请确认其存在。</p>
<p><code>问题：这里为什么要重塑为（227,227，batch_size）？</code></p>
<h3 id="训练模型生成anomalydetector.h5文件">2.训练模型（生成AnomalyDetector.h5文件）</h3>
<p>现在已经创建了trainer.npy，我们可以运行以下代码并使用它来生成异常检测器模型。这样创建的模型将称为AnomalyDetector.h5。</p>
<h4 id="相关函数解释">相关函数解释：</h4>
<h5 id="keras.callbacks">keras.callbacks:</h5>
<ul>
<li><p>```python ModelCheckpoint( filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1 ) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">  用于在每个训练期之后保存模型</span><br><span class="line"></span><br><span class="line">  - filepath:字符串，保存模型的路径。</span><br><span class="line"></span><br><span class="line">  - monitor:被监测的数据。</span><br><span class="line"></span><br><span class="line">  - verbose:详细信息模式，0或者1 。</span><br><span class="line"></span><br><span class="line">  - save_best_only: 如果save_best_only&#x3D;True，被监测数据的最佳模型就不会被覆盖。</span><br><span class="line"></span><br><span class="line">  - mode:&#123;auto, min, max&#125;的其中之一。</span><br><span class="line"></span><br><span class="line">    如果save_best_only&#x3D;True，那么是否覆盖保存文件的决定就取决于被监测数据的最大或者最小值。</span><br><span class="line"></span><br><span class="line">    对于val_acc，模式就会是max，而对于val_loss，模式就需要是min，等等。</span><br><span class="line"></span><br><span class="line">    在auto模式中，方向会自动从被监测的数据的名字中判断出来。</span><br><span class="line"></span><br><span class="line">  - save_weights_only:如果True，那么只有模型的权重会被保存(model.save_weights(filepath))，否则的话，整个模型会被保存 (model.save(filepath))。</span><br><span class="line"></span><br><span class="line">  - period:每个检查点之间的间隔（训练轮数）。</span><br><span class="line"></span><br><span class="line">- &#96;&#96;&#96;python</span><br><span class="line">  EarlyStopping(</span><br><span class="line">      monitor&#x3D;&#39;val_loss&#39;, </span><br><span class="line">      min_delta&#x3D;0, patience&#x3D;0, </span><br><span class="line">      verbose&#x3D;0, mode&#x3D;&#39;auto&#39;, </span><br><span class="line">      baseline&#x3D;None, </span><br><span class="line">      restore_best_weights&#x3D;False</span><br><span class="line">  )</span><br></pre></td></tr></table></figure></p>
<p>当被监测的数量不再提升，则停止训练。</p>
<ul>
<li><p>monitor:被监测的数据。</p></li>
<li><p>min_delta:在被监测的数据中被认为是提升的最小变化，例如，小于min_delta的绝对变化会被认为没有提升。</p></li>
<li><p>patience:没有进步的训练轮数，在这之后训练就会被停止。</p></li>
<li><p>verbose:详细信息模式。</p></li>
<li><p>mode:{auto, min, max}其中之一。</p>
<p>在min模式中，当被监测的数据停止下降，训练就会停止；</p>
<p>在max模式中，当被监测的数据停止上升，训练就会停止；</p>
<p>在auto模式中，方向会自动从被监测的数据的名字中判断出来。</p></li>
<li><p>baseline:要监控的数量的基准值.如果模型没有显示基准的改善，训练将停止。</p></li>
<li><p>restore_best_weights:是否从具有监测数量的最佳值的时期恢复模型权重。如果为False，则使用在训练的最后一步获得的模型权重。</p></li>
</ul></li>
</ul>
<h5 id="keras.layers">keras.layers:</h5>
<ul>
<li><p>```python Conv3D( filters, kernel_size, strides=(1, 1, 1), padding='valid', data_format=None, dilation_rate=(1, 1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None ) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">  三维卷积对三维的输入进行滑动窗卷积，当使用该层作为第一层时，应提供&#96;input_shape&#96;参数。例如&#96;input_shape &#x3D; (3,10,128,128)&#96;代表对10帧128*128的彩色RGB图像进行卷积。数据的通道位置仍然有&#96;data_format&#96;参数指定。</span><br><span class="line"></span><br><span class="line">  - filters：卷积核的数目（即输出的维度）</span><br><span class="line">  - kernel_size：一个整数，或者3 个整数表示的元组或列表， 指明3D 卷积窗口的深度、高度和宽度。 可以是一个整数，为所有空间维度指定相同的值。</span><br><span class="line">  - strides：单个整数或由3个整数构成的list&#x2F;tuple，为卷积的步长。如为单个整数，则表示在各个空间维度的相同步长。任何不为1的strides均与任何不为1的dilation_rate均不兼容</span><br><span class="line">  - padding：补0策略，为“valid”, “same” 。“valid”代表只进行有效的卷积，即对边界数据不处理。“same”代表保留边界处的卷积结果，通常会导致输出shape与输入shape相同。</span><br><span class="line">  - activation：激活函数，为预定义的激活函数名（参考[激活函数](https:&#x2F;&#x2F;keras-cn.readthedocs.io&#x2F;en&#x2F;latest&#x2F;other&#x2F;activations)），或逐元素（element-wise）的Theano函数。如果不指定该参数，将不会使用任何激活函数（即使用线性激活函数：a(x)&#x3D;x）</span><br><span class="line">  - dilation_rate：单个整数或由3个个整数构成的list&#x2F;tuple，指定dilated convolution中的膨胀比例。任何不为1的dilation_rate均与任何不为1的strides均不兼容。</span><br><span class="line">  - data_format：字符串，“channels_first”或“channels_last”之一，代表数据的通道维的位置。该参数是Keras 1.x中的image_dim_ordering，“channels_last”对应原本的“tf”，“channels_first”对应原本的“th”。以128x128x128的数据为例，“channels_first”应将数据组织为（3,128,128,128），而“channels_last”应将数据组织为（128,128,128,3）。该参数的默认值是&#96;~&#x2F;.keras&#x2F;keras.json&#96;中设置的值，若从未设置过，则为“channels_last”。</span><br><span class="line">  - use_bias:布尔值，是否使用偏置项</span><br><span class="line">  - kernel_initializer：权值初始化方法，为预定义初始化方法名的字符串，或用于初始化权重的初始化器。参考[initializers](https:&#x2F;&#x2F;keras-cn.readthedocs.io&#x2F;en&#x2F;latest&#x2F;other&#x2F;initializations)</span><br><span class="line">  - bias_initializer：权值初始化方法，为预定义初始化方法名的字符串，或用于初始化权重的初始化器。参考[initializers](https:&#x2F;&#x2F;keras-cn.readthedocs.io&#x2F;en&#x2F;latest&#x2F;other&#x2F;initializations)</span><br><span class="line">  - kernel_regularizer：施加在权重上的正则项，为[Regularizer](https:&#x2F;&#x2F;keras-cn.readthedocs.io&#x2F;en&#x2F;latest&#x2F;other&#x2F;regularizers)对象</span><br><span class="line">  - bias_regularizer：施加在偏置向量上的正则项，为[Regularizer](https:&#x2F;&#x2F;keras-cn.readthedocs.io&#x2F;en&#x2F;latest&#x2F;other&#x2F;regularizers)对象</span><br><span class="line">  - activity_regularizer：施加在输出上的正则项，为[Regularizer](https:&#x2F;&#x2F;keras-cn.readthedocs.io&#x2F;en&#x2F;latest&#x2F;other&#x2F;regularizers)对象</span><br><span class="line">  - kernel_constraints：施加在权重上的约束项，为[Constraints](https:&#x2F;&#x2F;keras-cn.readthedocs.io&#x2F;en&#x2F;latest&#x2F;other&#x2F;constraints)对象</span><br><span class="line">  - bias_constraints：施加在偏置上的约束项，为[Constraints](https:&#x2F;&#x2F;keras-cn.readthedocs.io&#x2F;en&#x2F;latest&#x2F;other&#x2F;constraints)对象</span><br><span class="line"></span><br><span class="line">- &#96;&#96;&#96;python</span><br><span class="line">  ConvLSTM2D(</span><br><span class="line">      filters,</span><br><span class="line">      kernel_size,</span><br><span class="line">      strides&#x3D;(1, 1),</span><br><span class="line">      padding&#x3D;&quot;valid&quot;,</span><br><span class="line">      data_format&#x3D;None,</span><br><span class="line">      dilation_rate&#x3D;(1, 1),</span><br><span class="line">      activation&#x3D;&quot;tanh&quot;,</span><br><span class="line">      recurrent_activation&#x3D;&quot;hard_sigmoid&quot;,</span><br><span class="line">      use_bias&#x3D;True,</span><br><span class="line">      kernel_initializer&#x3D;&quot;glorot_uniform&quot;,</span><br><span class="line">      recurrent_initializer&#x3D;&quot;orthogonal&quot;,</span><br><span class="line">      bias_initializer&#x3D;&quot;zeros&quot;,</span><br><span class="line">      unit_forget_bias&#x3D;True,</span><br><span class="line">      kernel_regularizer&#x3D;None,</span><br><span class="line">      recurrent_regularizer&#x3D;None,</span><br><span class="line">      bias_regularizer&#x3D;None,</span><br><span class="line">      activity_regularizer&#x3D;None,</span><br><span class="line">      kernel_constraint&#x3D;None,</span><br><span class="line">      recurrent_constraint&#x3D;None,</span><br><span class="line">      bias_constraint&#x3D;None,</span><br><span class="line">      return_sequences&#x3D;False,</span><br><span class="line">      go_backwards&#x3D;False,</span><br><span class="line">      stateful&#x3D;False,</span><br><span class="line">      dropout&#x3D;0.0,</span><br><span class="line">      recurrent_dropout&#x3D;0.0,</span><br><span class="line">      **kwargs</span><br><span class="line">  )</span><br></pre></td></tr></table></figure></p>
<p>卷积LSTM。它类似于LSTM层，但是输入转换和递归转换都是卷积的。</p>
<ul>
<li>filter：整数，输出空间的维数（即卷积中输出过滤器的数量）。</li>
<li>kernel_size：一个整数或n个整数的元组/列表，指定卷积窗口的尺寸。</li>
<li>strides：整数或n个整数的元组/列表，指定卷积的步幅。指定任何跨步值！= 1与指定任何<code>dilation_rate</code>值！= 1 不兼容。</li>
<li>padding：<code>"valid"</code>或<code>"same"</code>（不区分大小写）之一。</li>
<li>data_format：字符串，<code>channels_last</code>（默认）或之一<code>channels_first</code>。输入中尺寸的顺序。 <code>channels_last</code>对应于具有形状的输入， <code>(batch, time, ..., channels)</code> 而<code>channels_first</code>对应于具有形状的输入<code>(batch, time, channels, ...)</code>。默认为<code>image_data_format</code>在Keras配置文件中找到的值<code>~/.keras/keras.json</code>。如果你从未设置，那么它将是“ channels_last”。</li>
<li>dilation_rate：一个整数或n个整数的元组/列表，指定用于膨胀卷积的膨胀率。当前，指定任何<code>dilation_rate</code>值！= 1与指定任何<code>strides</code>值！= 1 不兼容。</li>
<li>activation：要使用的激活功能。默认情况下，将应用双曲线切线激活函数（<code>tanh(x)</code>）。</li>
<li>recurrent_activation：用于循环步骤的激活函数。</li>
<li>use_bias：布尔值，层是否使用偏置向量。</li>
<li>kernel_initializer：<code>kernel</code>权重矩阵的初始化程序，用于输入的线性转换。</li>
<li>recurrent_initializer：<code>recurrent_kernel</code> 权重矩阵的初始化程序，用于循环状态的线性转换。</li>
<li>bias_initializer：偏差向量的初始化器。</li>
<li>unit_forget_bias：布尔值。如果为True，则在初始化时将1加到忘记门的偏置上。与结合使用<code>bias_initializer="zeros"</code>。<a target="_blank" rel="noopener" href="http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf">Jozefowicz等人（2015</a>）建议使用</li>
<li>kernel_regularizer：将正则化函数应用于<code>kernel</code>权重矩阵。</li>
<li>recurrent_regularizer：正则化函数应用于<code>recurrent_kernel</code>权重矩阵。</li>
<li>bias_regularizer：将正则化函数应用于偏差向量。</li>
<li>activity_regularizer：应用于正则函数。</li>
<li>kernel_constraint：应用于<code>kernel</code>权重矩阵的约束函数。</li>
<li>recurrent_constraint：应用于<code>recurrent_kernel</code>权重矩阵的约束函数。</li>
<li>bias_constraint：应用于偏差向量的约束函数。</li>
<li>return_sequences：布尔值。是返回输出序列中的最后一个输出还是完整序列。</li>
<li>go_backwards：布尔值（默认为False）。如果为True，则向后处理输入序列。</li>
<li>stateful：布尔值（默认为False）。如果为True，则批次中索引i的每个样本的最后状态将用作下一个批次中索引i的样本的初始状态。</li>
<li>dropout：在0到1之间浮动。输入线性转换要下降的单位的分数。</li>
<li>recurrent_dropout：在0到1之间浮动。在递归状态的线性转换中要下降的单位的分数。</li>
</ul></li>
<li><p>```python Conv3DTranspose( filters, kernel_size, strides=(1, 1, 1), padding="valid", output_padding=None, data_format=None, dilation_rate=(1, 1, 1), activation=None, use_bias=True, kernel_initializer="glorot_uniform", bias_initializer="zeros", kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs ) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">  转置3D卷积层(有时称为3D解卷积)。</span><br><span class="line"></span><br><span class="line">  - filters：整数,输出空间的维数(即卷积中的滤波器数).</span><br><span class="line">  - kernel_size：3个整数的整数或元组&#x2F;列表,指定3D卷积窗口的深度,高度和宽度；可以是单个整数,以指定所有空间维度的相同值.</span><br><span class="line">  - strides：3个整数的整数或元组&#x2F;列表,指定沿深度,高度和宽度的卷积的步幅；可以是单个整数,以指定所有空间维度的相同值.</span><br><span class="line">  - padding：可以是一个&quot;valid&quot;或&quot;same&quot;(不区分大小写).</span><br><span class="line">  - data_format：一个字符串,可以为channels_last(默认)或channels_first,表示输入中维度的顺序,channels_last对应于具有形状(batch, depth, height, width, channels)的输入,而channels_first对应于具有形状(batch, channels, depth, height, width)的输入.</span><br><span class="line">  - dilation_rate：一个整数或3个整数的元组&#x2F;列表，指定用于扩张卷积的扩张率。可以是单个整数，以为所有空间尺寸指定相同的值。当前，指定任何&#96;dilation_rate&#96;值！&#x3D; 1与指定任何步幅值！&#x3D; 1不兼容。</span><br><span class="line">  - activation：激活功能.将其设置为None以保持线性激活.</span><br><span class="line">  - use_bias：Boolean,该层是否使用偏差.</span><br><span class="line">  - kernel_initializer：卷积内核的初始化程序.</span><br><span class="line">  - bias_initializer：偏置向量的初始化器,如果为None,将使用默认初始值设定项.</span><br><span class="line">  - kernel_regularizer：卷积内核的可选正则化器.</span><br><span class="line">  - bias_regularizer：偏置矢量的可选正则化器.</span><br><span class="line">  - activity_regularizer：输出的可选正则化函数.</span><br><span class="line">  - kernel_constraint：由Optimizer更新后应用于内核的可选投影函数(例如,用于实现层权重的范数约束或值约束).该函数必须将未投影的变量作为输入,并且必须返回投影变量(必须具有相同的形状).在进行异步分布式培训时,使用约束是不安全的.</span><br><span class="line">  - bias_constraint：由Optimizer更新后应用于偏差的可选投影函数.</span><br><span class="line">  - trainable：Boolean,如果为True还将变量添加到图集合GraphKeys.TRAINABLE_VARIABLES中(请参阅参考资料tf.Variable).</span><br><span class="line">  - name：字符串,图层的名称.</span><br><span class="line"></span><br><span class="line">- &#96;&#96;&#96;python</span><br><span class="line">  model.fit(</span><br><span class="line">  self, </span><br><span class="line">  x&#x3D;None, </span><br><span class="line">  y&#x3D;None, </span><br><span class="line">  batch_size&#x3D;None, </span><br><span class="line">  epochs&#x3D;1, </span><br><span class="line">  verbose&#x3D;1, </span><br><span class="line">  callbacks&#x3D;None, </span><br><span class="line">  validation_split&#x3D;0.0, </span><br><span class="line">  validation_data&#x3D;None, </span><br><span class="line">  shuffle&#x3D;True, </span><br><span class="line">  class_weight&#x3D;None, </span><br><span class="line">  sample_weight&#x3D;None, </span><br><span class="line">  initial_epoch&#x3D;0, </span><br><span class="line">  steps_per_epoch&#x3D;None, </span><br><span class="line">  validation_steps&#x3D;None</span><br><span class="line">  )</span><br></pre></td></tr></table></figure></p>
<ul>
<li>x：输入数据。如果模型只有一个输入，那么x的类型是numpy array，如果模型有多个输入，那么x的类型应当为list，list的元素是对应于各个输入的numpy array。如果模型的每个输入都有名字，则可以传入一个字典，将输入名与其输入数据对应起来。</li>
<li>y：标签，numpy array。如果模型有多个输出，可以传入一个numpy array的list。如果模型的输出拥有名字，则可以传入一个字典，将输出名与其标签对应起来。</li>
<li>batch_size：整数，指定进行梯度下降时每个batch包含的样本数。训练时一个batch的样本会被计算一次梯度下降，使目标函数优化一步。</li>
<li>epochs：整数，训练终止时的epoch值，训练将在达到该epoch值时停止，当没有设置initial_epoch时，它就是训练的总轮数，否则训练的总轮数为epochs - inital_epoch</li>
<li>verbose：日志显示，0为不在标准输出流输出日志信息，1为输出进度条记录，2为每个epoch输出一行记录</li>
<li>callbacks：list，其中的元素是<code>keras.callbacks.Callback</code>的对象。这个list中的回调函数将会在训练过程中的适当时机被调用，参考<a target="_blank" rel="noopener" href="https://keras-cn.readthedocs.io/en/latest/other/callbacks/">回调函数</a></li>
<li>validation_split：0~1之间的浮点数，用来指定训练集的一定比例数据作为验证集。验证集将不参与训练，并在每个epoch结束后测试的模型的指标，如损失函数、精确度等。注意，validation_split的划分在shuffle之后，因此如果你的数据本身是有序的，需要先手工打乱再指定validation_split，否则可能会出现验证集样本不均匀。</li>
<li>validation_data：形式为（X，y）或（X，y，sample_weights）的tuple，是指定的验证集。此参数将覆盖validation_spilt。</li>
<li>shuffle：布尔值，表示是否在训练过程中每个epoch前随机打乱输入样本的顺序。</li>
<li>class_weight：字典，将不同的类别映射为不同的权值，该参数用来在训练过程中调整损失函数（只能用于训练）。该参数在处理非平衡的训练数据（某些类的训练样本数很少）时，可以使得损失函数对样本数不足的数据更加关注。</li>
<li>sample_weight：权值的numpy array，用于在训练时调整损失函数（仅用于训练）。可以传递一个1D的与样本等长的向量用于对样本进行1对1的加权，或者在面对时序数据时，传递一个的形式为（samples，sequence_length）的矩阵来为每个时间步上的样本赋不同的权。这种情况下请确定在编译模型时添加了<code>sample_weight_mode='temporal'</code>。</li>
<li>initial_epoch: 从该参数指定的epoch开始训练，在继续之前的训练时有用。</li>
<li>steps_per_epoch: 一个epoch包含的步数（每一步是一个batch的数据送入），当使用如TensorFlow数据Tensor之类的输入张量进行训练时，默认的None代表自动分割，即数据集样本数/batch样本数。</li>
<li>validation_steps: 仅当steps_per_epoch被指定时有用，在验证集上的step总数。</li>
</ul></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint, EarlyStopping</span><br><span class="line"><span class="comment">#ModelCheckpoint(filepath, monitor=&#x27;val_loss&#x27;, verbose=0, save_best_only=False, save_weights_only=False, mode=&#x27;auto&#x27;, period=1)</span></span><br><span class="line"><span class="comment">#用于在每个训练期之后保存模型</span></span><br><span class="line"><span class="comment">#EarlyStopping(monitor=&#x27;val_loss&#x27;, min_delta=0, patience=0, verbose=0, mode=&#x27;auto&#x27;, baseline=None, restore_best_weights=False)</span></span><br><span class="line"><span class="comment">#当被监测的数量不再提升，则停止训练。</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv3D,ConvLSTM2D,Conv3DTranspose</span><br><span class="line"><span class="comment">#COnv3D三维卷积</span></span><br><span class="line"><span class="comment">#ConvLSTM2D 卷积LSTM。它类似于LSTM层，但是输入转换和递归转换都是卷积的。</span></span><br><span class="line"><span class="comment">#Conv3DTranspose 转置3D卷积层(有时称为3D解卷积).</span></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="comment">#Sequential顺序模型是多个网络层的线性堆叠。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#load_model是用的别人的:----------------------------------------------------</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_model</span>():</span></span><br><span class="line">	<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">	返回用于异常事件的模型</span></span><br><span class="line"><span class="string">	使用时空自动编码器检测视频</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">	&quot;&quot;&quot;</span></span><br><span class="line">	model=Sequential()<span class="comment">#创建一个顺序模型</span></span><br><span class="line">	model.add(Conv3D(filters=<span class="number">128</span>,kernel_size=(<span class="number">11</span>,<span class="number">11</span>,<span class="number">1</span>),strides=(<span class="number">4</span>,<span class="number">4</span>,<span class="number">1</span>),padding=<span class="string">&#x27;valid&#x27;</span>,input_shape=(<span class="number">227</span>,<span class="number">227</span>,<span class="number">10</span>,<span class="number">1</span>),activation=<span class="string">&#x27;tanh&#x27;</span>))</span><br><span class="line">  <span class="comment">#128层过滤器，3D卷积窗口的深度、高度、宽度为(11,11,1)，沿深度、高度、宽度的步长为(4,4,1)，padding为不填充，input_shape指定输入</span></span><br><span class="line">	model.add(Conv3D(filters=<span class="number">64</span>,kernel_size=(<span class="number">5</span>,<span class="number">5</span>,<span class="number">1</span>),strides=(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>),padding=<span class="string">&#x27;valid&#x27;</span>,activation=<span class="string">&#x27;tanh&#x27;</span>))</span><br><span class="line">  <span class="comment">#使用add方法将各层添加到模型中</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	model.add(ConvLSTM2D(filters=<span class="number">64</span>,kernel_size=(<span class="number">3</span>,<span class="number">3</span>),strides=<span class="number">1</span>,padding=<span class="string">&#x27;same&#x27;</span>,dropout=<span class="number">0.4</span>,recurrent_dropout=<span class="number">0.3</span>,return_sequences=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">	model.add(ConvLSTM2D(filters=<span class="number">32</span>,kernel_size=(<span class="number">3</span>,<span class="number">3</span>),strides=<span class="number">1</span>,padding=<span class="string">&#x27;same&#x27;</span>,dropout=<span class="number">0.3</span>,return_sequences=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">	model.add(ConvLSTM2D(filters=<span class="number">64</span>,kernel_size=(<span class="number">3</span>,<span class="number">3</span>),strides=<span class="number">1</span>,return_sequences=<span class="literal">True</span>, padding=<span class="string">&#x27;same&#x27;</span>,dropout=<span class="number">0.5</span>))</span><br><span class="line"></span><br><span class="line">	model.add(Conv3DTranspose(filters=<span class="number">128</span>,kernel_size=(<span class="number">5</span>,<span class="number">5</span>,<span class="number">1</span>),strides=(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>),padding=<span class="string">&#x27;valid&#x27;</span>,activation=<span class="string">&#x27;tanh&#x27;</span>))</span><br><span class="line">	model.add(Conv3DTranspose(filters=<span class="number">1</span>,kernel_size=(<span class="number">11</span>,<span class="number">11</span>,<span class="number">1</span>),strides=(<span class="number">4</span>,<span class="number">4</span>,<span class="number">1</span>),padding=<span class="string">&#x27;valid&#x27;</span>,activation=<span class="string">&#x27;tanh&#x27;</span>))</span><br><span class="line"></span><br><span class="line">	model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,loss=<span class="string">&#x27;mean_squared_error&#x27;</span>,metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">  <span class="comment">#optimizer=优化器,loss=损失函数(这里用的均方误差),metrics包含评估模型在训练和测试时的性能的指标，常用方法是metrics=[&#x27;accuracy&#x27;]</span></span><br><span class="line">	<span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="comment">#load_model ends here :----------------------------------------------------</span></span><br><span class="line"></span><br><span class="line">X_train=np.load(<span class="string">&#x27;trainer.npy&#x27;</span>)<span class="comment">#读取trainer中的数据存入X_train</span></span><br><span class="line">frames=X_train.shape[<span class="number">2</span>]<span class="comment">#帧数是读取数据中的第三维</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#需要将帧数除以10以减轻load_model</span></span><br><span class="line"><span class="comment">#Need to make number of frames divisible by 10 to ease the load_model</span></span><br><span class="line">frames=frames-frames%<span class="number">10</span></span><br><span class="line"></span><br><span class="line">X_train=X_train[:,:,:frames]</span><br><span class="line">X_train=X_train.reshape(-<span class="number">1</span>,<span class="number">227</span>,<span class="number">227</span>,<span class="number">10</span>)</span><br><span class="line"><span class="comment">#对数组重新分割，后三个维度分别为227，227，10</span></span><br><span class="line"><span class="comment">#数组新的shape属性应该要与原来的配套，如果等于-1的话，那么Numpy会根据剩下的维度计算出数组的另外一个shape属性值。</span></span><br><span class="line">X_train=np.expand_dims(X_train,axis=<span class="number">4</span>)</span><br><span class="line"><span class="comment">#扩展维度，np.expand_dims(a,axis=)即在a的相应的axis轴上扩展维度,这里是在X_train的第四个维度上再分一次，分出第五个维度</span></span><br><span class="line">Y_train=X_train.copy()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">epochs=<span class="number">200</span><span class="comment">#迭代次数，也就是全数据集</span></span><br><span class="line">batch_size=<span class="number">1</span><span class="comment">#批尺寸，决定的是下降的方向。batch_Size=1，是在线学习(Online Learning)，比较通俗的说就是每次处理多少个数据集，可以合理利用内存容量</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">  <span class="comment">#前面都是加载过程</span></span><br><span class="line">	model=load_model()<span class="comment">#处理数据返回异常行为模型</span></span><br><span class="line"></span><br><span class="line">	callback_save = ModelCheckpoint(<span class="string">&quot;AnomalyDetector.h5&quot;</span>,</span><br><span class="line">									monitor=<span class="string">&quot;mean_squared_error&quot;</span>)<span class="comment">#保存模型</span></span><br><span class="line"></span><br><span class="line">	callback_early_stopping = EarlyStopping(monitor=<span class="string">&#x27;val_loss&#x27;</span>, patience=<span class="number">3</span>)<span class="comment">#检测数量不再提升后停止</span></span><br><span class="line"></span><br><span class="line">	print(<span class="string">&#x27;Trainer has been loaded&#x27;</span>)</span><br><span class="line">  <span class="comment">#开始训练</span></span><br><span class="line">	model.fit(X_train,Y_train,</span><br><span class="line">			  batch_size=batch_size,</span><br><span class="line">			  epochs=epochs,</span><br><span class="line">			  callbacks = [callback_save,callback_early_stopping]</span><br><span class="line">			  )</span><br><span class="line"> <span class="comment">#x表示输入数据，y是它的对应的标签，callbacks表示训练过程中调用的函数</span></span><br><span class="line">print(<span class="string">&#x27;Done\n Please wait while AnomalyDetector.h5 has been created \nRefresh when needed&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>这部分代码跑的时间比较长，结果：</p>
<blockquote>
<p>Trainer has been loaded Epoch 1/200 22/22 [==============================] - 58s 2s/step - loss: 0.2591 - accuracy: 0.5241 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 2/200 22/22 [==============================] - 52s 2s/step - loss: 0.2062 - accuracy: 0.5479 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 3/200 22/22 [==============================] - 52s 2s/step - loss: 0.1938 - accuracy: 0.5523 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 4/200 22/22 [==============================] - 51s 2s/step - loss: 0.1276 - accuracy: 0.6697 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 5/200 22/22 [==============================] - 51s 2s/step - loss: 0.1060 - accuracy: 0.6921 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 6/200 22/22 [==============================] - 52s 2s/step - loss: 0.0933 - accuracy: 0.7107 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 7/200 22/22 [==============================] - 52s 2s/step - loss: 0.0881 - accuracy: 0.7173 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 8/200 22/22 [==============================] - 52s 2s/step - loss: 0.0863 - accuracy: 0.7199 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 9/200 22/22 [==============================] - 52s 2s/step - loss: 0.0855 - accuracy: 0.7160 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 10/200 22/22 [==============================] - 52s 2s/step - loss: 0.0817 - accuracy: 0.7263 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 11/200 22/22 [==============================] - 52s 2s/step - loss: 0.0819 - accuracy: 0.7235 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 12/200 22/22 [==============================] - 52s 2s/step - loss: 0.0799 - accuracy: 0.7241 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 13/200 22/22 [==============================] - 53s 2s/step - loss: 0.0791 - accuracy: 0.7251 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 14/200 22/22 [==============================] - 53s 2s/step - loss: 0.0791 - accuracy: 0.7229 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 15/200 22/22 [==============================] - 53s 2s/step - loss: 0.0795 - accuracy: 0.7234 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 16/200 22/22 [==============================] - 51s 2s/step - loss: 0.0765 - accuracy: 0.7293 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 17/200 22/22 [==============================] - 52s 2s/step - loss: 0.0777 - accuracy: 0.7239 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 18/200 22/22 [==============================] - 53s 2s/step - loss: 0.0773 - accuracy: 0.7268 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 19/200 22/22 [==============================] - 52s 2s/step - loss: 0.0767 - accuracy: 0.7295 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 20/200 22/22 [==============================] - 53s 2s/step - loss: 0.0754 - accuracy: 0.7299 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 21/200 22/22 [==============================] - 53s 2s/step - loss: 0.0771 - accuracy: 0.7291 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 22/200 22/22 [==============================] - 53s 2s/step - loss: 0.0735 - accuracy: 0.7335 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 23/200 22/22 [==============================] - 52s 2s/step - loss: 0.0747 - accuracy: 0.7335 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 24/200 22/22 [==============================] - 52s 2s/step - loss: 0.0736 - accuracy: 0.7361 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 25/200 22/22 [==============================] - 52s 2s/step - loss: 0.0733 - accuracy: 0.7329 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 26/200 22/22 [==============================] - 53s 2s/step - loss: 0.0734 - accuracy: 0.7306 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 27/200 22/22 [==============================] - 52s 2s/step - loss: 0.0736 - accuracy: 0.7316 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 28/200 22/22 [==============================] - 53s 2s/step - loss: 0.0710 - accuracy: 0.7354 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 29/200 22/22 [==============================] - 52s 2s/step - loss: 0.0714 - accuracy: 0.7377 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 30/200 22/22 [==============================] - 53s 2s/step - loss: 0.0708 - accuracy: 0.7388 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 31/200 22/22 [==============================] - 53s 2s/step - loss: 0.0709 - accuracy: 0.7371 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 32/200 22/22 [==============================] - 53s 2s/step - loss: 0.0696 - accuracy: 0.7407 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 33/200 22/22 [==============================] - 52s 2s/step - loss: 0.0714 - accuracy: 0.7342 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 34/200 22/22 [==============================] - 52s 2s/step - loss: 0.0714 - accuracy: 0.7319 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 35/200 22/22 [==============================] - 53s 2s/step - loss: 0.0704 - accuracy: 0.7352 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 36/200 22/22 [==============================] - 53s 2s/step - loss: 0.0688 - accuracy: 0.7380 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 37/200 22/22 [==============================] - 53s 2s/step - loss: 0.0702 - accuracy: 0.7359 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 38/200 22/22 [==============================] - 53s 2s/step - loss: 0.0697 - accuracy: 0.7368 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 39/200 22/22 [==============================] - 52s 2s/step - loss: 0.0690 - accuracy: 0.7377 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 40/200 22/22 [==============================] - 53s 2s/step - loss: 0.0704 - accuracy: 0.7336 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 41/200 22/22 [==============================] - 54s 2s/step - loss: 0.0697 - accuracy: 0.7351 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 42/200 22/22 [==============================] - 53s 2s/step - loss: 0.0695 - accuracy: 0.7371 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 43/200 22/22 [==============================] - 53s 2s/step - loss: 0.0682 - accuracy: 0.7411 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 44/200 22/22 [==============================] - 53s 2s/step - loss: 0.0681 - accuracy: 0.7399 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 45/200 22/22 [==============================] - 53s 2s/step - loss: 0.0696 - accuracy: 0.7362 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 46/200 22/22 [==============================] - 53s 2s/step - loss: 0.0691 - accuracy: 0.7376 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 47/200 22/22 [==============================] - 53s 2s/step - loss: 0.0685 - accuracy: 0.7373 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 48/200 22/22 [==============================] - 53s 2s/step - loss: 0.0691 - accuracy: 0.7393 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 49/200 22/22 [==============================] - 53s 2s/step - loss: 0.0685 - accuracy: 0.7392 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 50/200 22/22 [==============================] - 52s 2s/step - loss: 0.0678 - accuracy: 0.7379 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 51/200 22/22 [==============================] - 52s 2s/step - loss: 0.0691 - accuracy: 0.7363 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 52/200 22/22 [==============================] - 55s 3s/step - loss: 0.0703 - accuracy: 0.7344 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 53/200 22/22 [==============================] - 54s 2s/step - loss: 0.0690 - accuracy: 0.7366 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 54/200 22/22 [==============================] - 53s 2s/step - loss: 0.0686 - accuracy: 0.7357 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 55/200 22/22 [==============================] - 53s 2s/step - loss: 0.0699 - accuracy: 0.7365 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 56/200 22/22 [==============================] - 53s 2s/step - loss: 0.0679 - accuracy: 0.7403 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 57/200 22/22 [==============================] - 53s 2s/step - loss: 0.0689 - accuracy: 0.7367 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 58/200 22/22 [==============================] - 53s 2s/step - loss: 0.0690 - accuracy: 0.7365 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 59/200 22/22 [==============================] - 53s 2s/step - loss: 0.0695 - accuracy: 0.7346 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 60/200 22/22 [==============================] - 54s 2s/step - loss: 0.0687 - accuracy: 0.7353 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 61/200 22/22 [==============================] - 53s 2s/step - loss: 0.0702 - accuracy: 0.7347 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 62/200 22/22 [==============================] - 53s 2s/step - loss: 0.0678 - accuracy: 0.7405 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 63/200 22/22 [==============================] - 53s 2s/step - loss: 0.0697 - accuracy: 0.7384 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 64/200 22/22 [==============================] - 53s 2s/step - loss: 0.0685 - accuracy: 0.7382 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 65/200 22/22 [==============================] - 52s 2s/step - loss: 0.0690 - accuracy: 0.7360 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 66/200 22/22 [==============================] - 52s 2s/step - loss: 0.0686 - accuracy: 0.7368 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 67/200 22/22 [==============================] - 52s 2s/step - loss: 0.0694 - accuracy: 0.7333 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 68/200 22/22 [==============================] - 53s 2s/step - loss: 0.0689 - accuracy: 0.7375 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 69/200 22/22 [==============================] - 53s 2s/step - loss: 0.0683 - accuracy: 0.7358 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 70/200 22/22 [==============================] - 53s 2s/step - loss: 0.0671 - accuracy: 0.7385 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 71/200 22/22 [==============================] - 52s 2s/step - loss: 0.0670 - accuracy: 0.7417 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 72/200 22/22 [==============================] - 52s 2s/step - loss: 0.0672 - accuracy: 0.7405 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 73/200 22/22 [==============================] - 53s 2s/step - loss: 0.0679 - accuracy: 0.7402 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 74/200 22/22 [==============================] - 52s 2s/step - loss: 0.0674 - accuracy: 0.7393 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 75/200 22/22 [==============================] - 53s 2s/step - loss: 0.0666 - accuracy: 0.7401 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 76/200 22/22 [==============================] - 53s 2s/step - loss: 0.0676 - accuracy: 0.7374 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 77/200 22/22 [==============================] - 52s 2s/step - loss: 0.0670 - accuracy: 0.7386 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 78/200 22/22 [==============================] - 53s 2s/step - loss: 0.0675 - accuracy: 0.7376 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 79/200 22/22 [==============================] - 52s 2s/step - loss: 0.0668 - accuracy: 0.7401 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 80/200 22/22 [==============================] - 52s 2s/step - loss: 0.0675 - accuracy: 0.7358 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 81/200 22/22 [==============================] - 52s 2s/step - loss: 0.0668 - accuracy: 0.7397 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 82/200 22/22 [==============================] - 52s 2s/step - loss: 0.0676 - accuracy: 0.7360 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 83/200 22/22 [==============================] - 52s 2s/step - loss: 0.0670 - accuracy: 0.7393 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 84/200 22/22 [==============================] - 53s 2s/step - loss: 0.0668 - accuracy: 0.7357 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 85/200 22/22 [==============================] - 52s 2s/step - loss: 0.0675 - accuracy: 0.7358 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 86/200 22/22 [==============================] - 52s 2s/step - loss: 0.0663 - accuracy: 0.7388 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 87/200 22/22 [==============================] - 53s 2s/step - loss: 0.0672 - accuracy: 0.7378 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 88/200 22/22 [==============================] - 53s 2s/step - loss: 0.0671 - accuracy: 0.7373 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 89/200 22/22 [==============================] - 52s 2s/step - loss: 0.0672 - accuracy: 0.7377 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 90/200 22/22 [==============================] - 52s 2s/step - loss: 0.0670 - accuracy: 0.7374 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 91/200 22/22 [==============================] - 53s 2s/step - loss: 0.0671 - accuracy: 0.7376 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 92/200 22/22 [==============================] - 53s 2s/step - loss: 0.0657 - accuracy: 0.7400 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 93/200 22/22 [==============================] - 53s 2s/step - loss: 0.0654 - accuracy: 0.7394 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 94/200 22/22 [==============================] - 52s 2s/step - loss: 0.0651 - accuracy: 0.7399 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 95/200 22/22 [==============================] - 53s 2s/step - loss: 0.0661 - accuracy: 0.7412 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 96/200 22/22 [==============================] - 52s 2s/step - loss: 0.0671 - accuracy: 0.7338 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 97/200 22/22 [==============================] - 53s 2s/step - loss: 0.0648 - accuracy: 0.7411 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 98/200 22/22 [==============================] - 53s 2s/step - loss: 0.0655 - accuracy: 0.7394 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 99/200 22/22 [==============================] - 53s 2s/step - loss: 0.0656 - accuracy: 0.7375 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 100/200 22/22 [==============================] - 52s 2s/step - loss: 0.0656 - accuracy: 0.7406 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 101/200 22/22 [==============================] - 52s 2s/step - loss: 0.0657 - accuracy: 0.7365 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 102/200 22/22 [==============================] - 52s 2s/step - loss: 0.0645 - accuracy: 0.7396 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 103/200 22/22 [==============================] - 53s 2s/step - loss: 0.0659 - accuracy: 0.7388 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 104/200 22/22 [==============================] - 53s 2s/step - loss: 0.0637 - accuracy: 0.7420 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 105/200 22/22 [==============================] - 53s 2s/step - loss: 0.0648 - accuracy: 0.7378 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 106/200 22/22 [==============================] - 52s 2s/step - loss: 0.0629 - accuracy: 0.7411 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 107/200 22/22 [==============================] - 52s 2s/step - loss: 0.0621 - accuracy: 0.7416 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 108/200 22/22 [==============================] - 52s 2s/step - loss: 0.0604 - accuracy: 0.7410 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 109/200 22/22 [==============================] - 53s 2s/step - loss: 0.0574 - accuracy: 0.7445 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 110/200 22/22 [==============================] - 53s 2s/step - loss: 0.0562 - accuracy: 0.7452 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 111/200 22/22 [==============================] - 53s 2s/step - loss: 0.0544 - accuracy: 0.7470 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 112/200 22/22 [==============================] - 52s 2s/step - loss: 0.0529 - accuracy: 0.7455 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 113/200 22/22 [==============================] - 52s 2s/step - loss: 0.0519 - accuracy: 0.7469 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 114/200 22/22 [==============================] - 52s 2s/step - loss: 0.0512 - accuracy: 0.7502 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 115/200 22/22 [==============================] - 53s 2s/step - loss: 0.0492 - accuracy: 0.7527 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 116/200 22/22 [==============================] - 53s 2s/step - loss: 0.0489 - accuracy: 0.7526 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 117/200 22/22 [==============================] - 52s 2s/step - loss: 0.0482 - accuracy: 0.7511 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 118/200 22/22 [==============================] - 53s 2s/step - loss: 0.0456 - accuracy: 0.7562 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 119/200 22/22 [==============================] - 53s 2s/step - loss: 0.0441 - accuracy: 0.7588 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 120/200 22/22 [==============================] - 53s 2s/step - loss: 0.0431 - accuracy: 0.7590 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 121/200 22/22 [==============================] - 53s 2s/step - loss: 0.0424 - accuracy: 0.7606 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 122/200 22/22 [==============================] - 53s 2s/step - loss: 0.0412 - accuracy: 0.7606 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 123/200 22/22 [==============================] - 53s 2s/step - loss: 0.0401 - accuracy: 0.7647 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 124/200 22/22 [==============================] - 53s 2s/step - loss: 0.0394 - accuracy: 0.7637 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 125/200 22/22 [==============================] - 53s 2s/step - loss: 0.0386 - accuracy: 0.7674 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 126/200 22/22 [==============================] - 52s 2s/step - loss: 0.0377 - accuracy: 0.7664 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 127/200 22/22 [==============================] - 52s 2s/step - loss: 0.0371 - accuracy: 0.7705 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 128/200 22/22 [==============================] - 52s 2s/step - loss: 0.0375 - accuracy: 0.7655 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 129/200 22/22 [==============================] - 52s 2s/step - loss: 0.0358 - accuracy: 0.7682 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 130/200 22/22 [==============================] - 52s 2s/step - loss: 0.0354 - accuracy: 0.7690 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 131/200 22/22 [==============================] - 52s 2s/step - loss: 0.0360 - accuracy: 0.7682 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 132/200 22/22 [==============================] - 52s 2s/step - loss: 0.0349 - accuracy: 0.7676 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 133/200 22/22 [==============================] - 53s 2s/step - loss: 0.0352 - accuracy: 0.7687 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 134/200 22/22 [==============================] - 52s 2s/step - loss: 0.0337 - accuracy: 0.7721 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 135/200 22/22 [==============================] - 53s 2s/step - loss: 0.0337 - accuracy: 0.7691 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 136/200 22/22 [==============================] - 52s 2s/step - loss: 0.0335 - accuracy: 0.7725 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 137/200 22/22 [==============================] - 53s 2s/step - loss: 0.0337 - accuracy: 0.7697 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 138/200 22/22 [==============================] - 54s 2s/step - loss: 0.0334 - accuracy: 0.7697 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 139/200 22/22 [==============================] - 54s 2s/step - loss: 0.0333 - accuracy: 0.7715 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 140/200 22/22 [==============================] - 53s 2s/step - loss: 0.0326 - accuracy: 0.7717 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 141/200 22/22 [==============================] - 53s 2s/step - loss: 0.0324 - accuracy: 0.7716 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 142/200 22/22 [==============================] - 52s 2s/step - loss: 0.0321 - accuracy: 0.7722 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 143/200 22/22 [==============================] - 53s 2s/step - loss: 0.0318 - accuracy: 0.7740 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 144/200 22/22 [==============================] - 53s 2s/step - loss: 0.0317 - accuracy: 0.7729 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 145/200 22/22 [==============================] - 54s 2s/step - loss: 0.0311 - accuracy: 0.7722 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 146/200 22/22 [==============================] - 53s 2s/step - loss: 0.0307 - accuracy: 0.7726 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 147/200 22/22 [==============================] - 53s 2s/step - loss: 0.0307 - accuracy: 0.7755 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 148/200 22/22 [==============================] - 53s 2s/step - loss: 0.0310 - accuracy: 0.7748 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 149/200 22/22 [==============================] - 53s 2s/step - loss: 0.0304 - accuracy: 0.7746 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 150/200 22/22 [==============================] - 52s 2s/step - loss: 0.0302 - accuracy: 0.7736 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 151/200 22/22 [==============================] - 53s 2s/step - loss: 0.0305 - accuracy: 0.7748 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 152/200 22/22 [==============================] - 53s 2s/step - loss: 0.0302 - accuracy: 0.7747 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 153/200 22/22 [==============================] - 53s 2s/step - loss: 0.0295 - accuracy: 0.7750 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 154/200 22/22 [==============================] - 53s 2s/step - loss: 0.0298 - accuracy: 0.7711 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 155/200 22/22 [==============================] - 53s 2s/step - loss: 0.0293 - accuracy: 0.7764 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 156/200 22/22 [==============================] - 53s 2s/step - loss: 0.0294 - accuracy: 0.7751 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 157/200 22/22 [==============================] - 53s 2s/step - loss: 0.0297 - accuracy: 0.7726 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 158/200 22/22 [==============================] - 53s 2s/step - loss: 0.0290 - accuracy: 0.7747 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 159/200 22/22 [==============================] - 52s 2s/step - loss: 0.0286 - accuracy: 0.7761 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 160/200 22/22 [==============================] - 53s 2s/step - loss: 0.0298 - accuracy: 0.7730 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 161/200 22/22 [==============================] - 54s 2s/step - loss: 0.0288 - accuracy: 0.7764 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 162/200 22/22 [==============================] - 53s 2s/step - loss: 0.0290 - accuracy: 0.7732 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 163/200 22/22 [==============================] - 54s 2s/step - loss: 0.0290 - accuracy: 0.7741 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 164/200 22/22 [==============================] - 54s 2s/step - loss: 0.0282 - accuracy: 0.7769 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 165/200 22/22 [==============================] - 53s 2s/step - loss: 0.0281 - accuracy: 0.7743 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 166/200 22/22 [==============================] - 54s 2s/step - loss: 0.0279 - accuracy: 0.7745 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 167/200 22/22 [==============================] - 53s 2s/step - loss: 0.0282 - accuracy: 0.7763 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 168/200 22/22 [==============================] - 53s 2s/step - loss: 0.0277 - accuracy: 0.7783 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 169/200 22/22 [==============================] - 53s 2s/step - loss: 0.0281 - accuracy: 0.7765 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 170/200 22/22 [==============================] - 53s 2s/step - loss: 0.0286 - accuracy: 0.7735 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 171/200 22/22 [==============================] - 53s 2s/step - loss: 0.0279 - accuracy: 0.7726 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 172/200 22/22 [==============================] - 53s 2s/step - loss: 0.0279 - accuracy: 0.7743 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 173/200 22/22 [==============================] - 54s 2s/step - loss: 0.0280 - accuracy: 0.7747 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 174/200 22/22 [==============================] - 53s 2s/step - loss: 0.0274 - accuracy: 0.7766 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 175/200 22/22 [==============================] - 53s 2s/step - loss: 0.0276 - accuracy: 0.7744 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 176/200 22/22 [==============================] - 53s 2s/step - loss: 0.0271 - accuracy: 0.7764 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 177/200 22/22 [==============================] - 53s 2s/step - loss: 0.0268 - accuracy: 0.7785 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 178/200 22/22 [==============================] - 53s 2s/step - loss: 0.0273 - accuracy: 0.7787 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 179/200 22/22 [==============================] - 53s 2s/step - loss: 0.0270 - accuracy: 0.7759 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 180/200 22/22 [==============================] - 53s 2s/step - loss: 0.0268 - accuracy: 0.7770 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 181/200 22/22 [==============================] - 53s 2s/step - loss: 0.0265 - accuracy: 0.7796 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 182/200 22/22 [==============================] - 53s 2s/step - loss: 0.0268 - accuracy: 0.7802 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 183/200 22/22 [==============================] - 53s 2s/step - loss: 0.0274 - accuracy: 0.7783 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 184/200 22/22 [==============================] - 53s 2s/step - loss: 0.0267 - accuracy: 0.7776 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 185/200 22/22 [==============================] - 53s 2s/step - loss: 0.0260 - accuracy: 0.7787 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 186/200 22/22 [==============================] - 53s 2s/step - loss: 0.0269 - accuracy: 0.7775 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 187/200 22/22 [==============================] - 53s 2s/step - loss: 0.0268 - accuracy: 0.7769 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 188/200 22/22 [==============================] - 53s 2s/step - loss: 0.0263 - accuracy: 0.7756 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 189/200 22/22 [==============================] - 53s 2s/step - loss: 0.0267 - accuracy: 0.7783 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 190/200 22/22 [==============================] - 53s 2s/step - loss: 0.0265 - accuracy: 0.7773 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 191/200 22/22 [==============================] - 52s 2s/step - loss: 0.0262 - accuracy: 0.7798 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 192/200 22/22 [==============================] - 53s 2s/step - loss: 0.0262 - accuracy: 0.7756 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 193/200 22/22 [==============================] - 53s 2s/step - loss: 0.0261 - accuracy: 0.7763 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 194/200 22/22 [==============================] - 53s 2s/step - loss: 0.0258 - accuracy: 0.7761 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 195/200 22/22 [==============================] - 53s 2s/step - loss: 0.0257 - accuracy: 0.7777 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 196/200 22/22 [==============================] - 52s 2s/step - loss: 0.0255 - accuracy: 0.7810 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 197/200 22/22 [==============================] - 52s 2s/step - loss: 0.0260 - accuracy: 0.7757 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 198/200 22/22 [==============================] - 52s 2s/step - loss: 0.0255 - accuracy: 0.7770 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 199/200 22/22 [==============================] - 53s 2s/step - loss: 0.0253 - accuracy: 0.7775 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Epoch 200/200 22/22 [==============================] - 53s 2s/step - loss: 0.0255 - accuracy: 0.7768 WARNING:tensorflow:Early stopping conditioned on metric <code>val_loss</code> which is not available. Available metrics are: loss,accuracy Done</p>
<p>Please wait while AnomalyDetector.h5 has been created Refresh when needed</p>
</blockquote>
<p>参考链接：<a target="_blank" rel="noopener" href="https://github.com/sambyte99/Crowd_Anomaly_Detection">Crowd_Anomaly_Detection</a></p>

      
    </div>
    
    
    

    

    

    
	

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/python/" rel="tag"># python</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2021/04/14/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E5%AE%9E%E7%8E%B0%E5%89%8D%E7%BC%80%E6%A0%91Trie/" rel="next" title="【算法】实现前缀树Trie">
                <i class="fa fa-chevron-left"></i> 【算法】实现前缀树Trie
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2021/04/21/%E3%80%90git%E3%80%91git%E5%A6%82%E4%BD%95%E4%B8%8A%E4%BC%A0%E8%B6%85%E8%BF%87100M%E7%9A%84%E5%A4%A7%E6%96%87%E4%BB%B6/" rel="prev" title="【git】git如何上传超过100M的大文件">
                【git】git如何上传超过100M的大文件 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/uploads/person.jpg"
                alt="" />
            
              <p class="site-author-name" itemprop="name"></p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">23</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">14</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/ChocoFairy" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:wanlizhao@mail.dlut.edu.cn" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E5%B7%A5%E5%85%B7"><span class="nav-number">1.</span> <span class="nav-text">一、工具</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8C%E4%BB%A3%E7%A0%81"><span class="nav-number">2.</span> <span class="nav-text">二、代码</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87%E7%94%9F%E6%88%90trainer.npy%E6%96%87%E4%BB%B6"><span class="nav-number">2.1.</span> <span class="nav-text">1.数据准备（生成trainer.npy文件）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%94%9F%E6%88%90anomalydetector.h5%E6%96%87%E4%BB%B6"><span class="nav-number">2.2.</span> <span class="nav-text">2.训练模型（生成AnomalyDetector.h5文件）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%9B%B8%E5%85%B3%E5%87%BD%E6%95%B0%E8%A7%A3%E9%87%8A"><span class="nav-number">2.2.1.</span> <span class="nav-text">相关函数解释：</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#keras.callbacks"><span class="nav-number">2.2.1.1.</span> <span class="nav-text">keras.callbacks:</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#keras.layers"><span class="nav-number">2.2.1.2.</span> <span class="nav-text">keras.layers:</span></a></li></ol></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">wlz</span>

  
</div>




  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>






        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  


  

  

  
  
   <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas> 
   <script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script> 
   <script type="text/javascript" src="/js/src/fireworks.js"></script>
  

   <!--<script type="text/javascript" src="//libs.baidu.com/jquery/2.1.3/jquery.min.js"></script>
   雪花特效2
  <script type="text/javascript" src="/js/snow2.js"></script>--> 
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/assets/koharu.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":true},"log":false});</script></body>
</html>

